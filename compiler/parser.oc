//* The parser

import @ast::nodes::*
import @ast::program::{ Namespace, Program }
import @lexer::Lexer
import @types::{ Type, BaseType, FunctionType, ArrayType }
import std::span::Span
import std::map::Map
import std::vector::Vector
import @tokens::{ Token, TokenType }
import @ast::scopes::{ Symbol, SymbolType, Template }
import @errors::Error
import std::libc::{ calloc, free }
import @utils::directory_exists

@compiler c_include "libgen.h"
def dirname(path: str): str extern
def basename(path: str): str extern

struct Parser {
    tokens: &Vector<&Token>
    curr: u32

    curr_func: &Function
    program: &Program
    ns: &Namespace
}

def Parser::make(program: &Program, ns: &Namespace): Parser {
    return Parser(
        tokens: null,
        curr: 0,
        curr_func: null,
        program: program,
        ns: ns
    )
}

def Parser::peek(&this, off: i32 = 1): &Token {
    let idx = .curr as i32 + off
    assert 0i32 <= idx < (.tokens.size as i32)
    return .tokens.at(idx as u32)
}

def Parser::error_msg(&this, msg: str): &Error {
    let err = Error::new(.token().span, msg)
    .program.errors.push(err)
    return err
}

def Parser::error(&this, err: &Error): &Error {
    .program.errors.push(err)
    return err
}

def Parser::unhandled_type(&this, func: str) {
    .error_msg(`Unexpected token in {func}: {.token().type.str()}`)
}

def Parser::token(&this): &Token => .tokens.at(.curr as u32)

def Parser::token_is(&this, type: TokenType): bool {
    if type == TokenType::Newline {
        return .token().seen_newline
    }
    return .token().type == type
}

def Parser::consume_if(&this, type: TokenType): bool {
    if .token_is(type) {
        // Newline tokens are special because they don't consume a token.
        if type != TokenType::Newline {
            .curr += 1
        }
        return true
    }
    return false
}

def Parser::consume_newline_or(&this, type: TokenType) {
    if .token_is(type) {
        .curr += 1
    } else if not .token().seen_newline {
        .error_msg(`Expected {type.str()} or newline`)
        .program.exit_with_errors()
    }
}

def Parser::consume(&this, type: TokenType): &Token {
    let tok = .token()
    if not .consume_if(type) {
        .error_msg(`Expected TokenType::{type.str()}`)
        .program.exit_with_errors()
    }
    return tok
}

def Parser::consume_end_of_statement(&this) {
    if .token_is(TokenType::CloseCurly) return
    .consume_newline_or(TokenType::Semicolon)
}

// NOTE: The parser _always_ returns an `Unresolved` base type, with the name of the type stored in
// the `name` field. The typechecker is responsible for resolving this, even for the built-in types.
def Parser::parse_type(&this): &Type => match .token().type {
    Identifier => {
        let ident = .parse_scoped_identifier()
        let name = if ident.type == ASTType::Identifier then ident.u.ident.name else "<unresolved>"
        let typ = Type::new_unresolved(name, ident.span)
        typ.u.unresolved = ident
        yield typ
    }

    Ampersand => {
        let amp = .consume(Ampersand)
        let base = .parse_type()
        let typ = Type::new_resolved(BaseType::Pointer, amp.span.join(base.span))
        typ.u.ptr = base
        yield typ
    }

    Fn => {
        let start_span = .token().span
        .consume(TokenType::Fn)
        .consume(TokenType::OpenParen)
        let params = Vector<&Variable>::new()
        while not .token_is(TokenType::CloseParen) {
            let param_type = .parse_type()

            // No names for parameters needed for function types
            let var = Variable::new(param_type)
            var.sym = Symbol::from_local_variable("", var, param_type.span)
            params.push(var)

            if not .token_is(TokenType::CloseParen) {
                .consume(TokenType::Comma)
            }
        }
        let close = .consume(TokenType::CloseParen)
        let return_type: &Type
        if .consume_if(TokenType::Colon) {
            return_type = .parse_type()
        } else {
            return_type = Type::new_unresolved_base(BaseType::Void, start_span)
        }
        let type = Type::new_resolved(BaseType::Function, start_span.join(close.span))
        type.u.func = FunctionType(null, params, return_type)
        yield type
    }

    OpenSquare => {
        let start_span = .token().span
        .consume(TokenType::OpenSquare)
        let elem_type = .parse_type()
        .consume(TokenType::Semicolon)
        let size_expr = .parse_expression(end_type: TokenType::CloseSquare)
        let close = .consume(TokenType::CloseSquare)
        let typ = Type::new_resolved(BaseType::Array, start_span.join(close.span))
        typ.u.arr = ArrayType(elem_type, size_expr)
        yield typ
    }

    else => {
        .unhandled_type("parse_type")
        yield Type::new_unresolved_base(BaseType::Error, .token().span)
    }
}

def Parser::parse_scoped_identifier(&this, consume_template: bool = true): &AST {
    let tok = .consume(TokenType::Identifier)
    let node = AST::new(ASTType::Identifier, tok.span)
    node.u.ident.name = tok.text

    while true {
        match .token().type {
            TokenType::ColonColon => {
                .consume(TokenType::ColonColon)
                let name = .consume(TokenType::Identifier)
                let lookup = AST::new(ASTType::NSLookup, node.span.join(name.span))
                lookup.u.lookup = NSLookup(node, name.text, name.span)
                node = lookup
            }
            TokenType::LessThan => {
                if not consume_template return node
                // FIXME: Is there a more robust way to do this?
                // We want to be able to differentiate between a `<` that starts a specialization and
                // a `<` that is part of a less-than comparison before typechecking, I don't know of
                // the best way to do this, but here's a couple heuristics:

                // 1. Make sure that we don't have a space between the identifier and the `<`
                let prev_token = .tokens.at(.curr as u32 - 1)
                if not .token().span.starts_right_after(prev_token.span) {
                    return node
                }

                // 2. Make sure the token after that isn't a `.`
                let next_next_token = .tokens.at(.curr as u32 + 2)
                if next_next_token.type == TokenType::Dot {
                    return node
                }

                // Okay... so we're kinda-sorta sure that this is a specialization, let's parse it.
                let start = .consume(TokenType::LessThan)
                let args = Vector<&Type>::new()

                while not .token_is(TokenType::GreaterThan) {
                    args.push(.parse_type())
                    if not .token_is(TokenType::GreaterThan) {
                        if not .consume_if(TokenType::Comma) {
                            .error(Error::new_note(
                                .token().span, "Parsing template specialization: expected `,` or `>`",
                                "If you're comparing values, put a space before the `<` earlier"
                            ))
                            return AST::new(ASTType::Error, node.span)
                        }
                    }
                }
                let end = .consume(TokenType::GreaterThan)
                let spec = AST::new(ASTType::Specialization, node.span.join(end.span))
                spec.u.spec = Specialization(base: node, template_args: args)
                node = spec
            }
            else => return node
        }
    }

    return null // unreachable
}


def Parser::parse_format_string(&this): &AST {
    let fstr = .consume(TokenType::FormatStringLiteral)
    let fstr_len = fstr.text.len()

    let expr_parts = Vector<str>::new()
    let expr_start = Vector<u32>::new()

    let format_parts = Vector<str>::new()
    let specifiers = Vector<str>::new()

    let specifier_loc = 0
    let specifier_found = false

    let count = 0
    let cur_start = 0

    for let i = 0; i < fstr_len; i += 1 {
        if fstr.text[i] == '\\' {
            i += 1
        } else if fstr.text[i] == '{' {
            if count == 0 {
                let part = fstr.text.substring(cur_start, i - cur_start)
                format_parts.push(part)
                cur_start = i + 1
            }
            count += 1
        } else if fstr.text[i] == '}' {
            count -= 1
            if count == 0 {
                if specifier_loc > 0 {
                    let len = specifier_loc - cur_start
                    let part = fstr.text.substring(cur_start, len)
                    expr_parts.push(part)
                    expr_start.push(cur_start)

                    specifier_loc += 1
                    while specifier_loc < i and fstr.text[specifier_loc] == ' ' {
                        specifier_loc += 1
                    }

                    if specifier_loc == i {
                        let loc = fstr.span.start;
                        loc.col += specifier_loc + 1
                        let span = Span(loc, loc)
                        .error(Error::new(span, "Expected format specifier"))
                        return null
                    }

                    let spec = fstr.text.substring(specifier_loc, i - specifier_loc)
                    specifiers.push(spec)
                } else {
                    let part = fstr.text.substring(cur_start, i - cur_start)
                    expr_parts.push(part)
                    expr_start.push(cur_start)
                    specifiers.push(null)
                }
                cur_start = i + 1
                specifier_loc = 0
                specifier_found = false

            } else if count < 0 {
                .error(Error::new(fstr.span, "Unmatched '}' in format string"))
                return null
            }

        } else if fstr.text[i] == ':' {
            // TODO: Handle errors properly (actually, maybe just add an assert)
            if count == 1 and fstr.text[i - 1] != ':' and fstr.text[i + 1] != ':' {
                specifier_loc = i
                specifier_found = true
            }
        }
    }
    if count != 0 {
        .error(Error::new(fstr.span, "Unmatched '{' in format string"))
        return null
    }
    let part = fstr.text.substring(cur_start, fstr_len - cur_start)
    format_parts.push(part)

    let node = AST::new(ASTType::FormatStringLiteral, fstr.span)
    node.u.fmt_str.parts = format_parts

    let fstr_start = fstr.span.start
    let expr_nodes = Vector<&AST>::new()
    for let i = 0; i < expr_parts.size; i += 1 {
        let part = expr_parts.at(i)
        let start = expr_start.at(i)

        let lexer = Lexer::make(part, fstr_start.filename)
        lexer.loc = fstr_start
        lexer.loc.col += start + 1

        let tokens = lexer.lex()
        for error : lexer.errors.iter() {
            .error(error)
        }
        lexer.errors.free()

        let sub_parser = Parser::make(.program, .ns)
        sub_parser.tokens = tokens
        sub_parser.curr = 0
        sub_parser.curr_func = .curr_func

        let expr = sub_parser.parse_expression(end_type: TokenType::CloseCurly)
        if not sub_parser.token_is(TokenType::EOF) {
            .error(Error::new(expr.span, "Invalid expression in format string"))
        }

        expr_nodes.push(expr)
    }
    node.u.fmt_str.exprs = expr_nodes
    node.u.fmt_str.specs = specifiers
    expr_parts.free()
    expr_start.free()
    return node
}

def Parser::parse_match(&this): &AST {
    let op = .consume(TokenType::Match)
    let expr = .parse_expression(end_type: TokenType::OpenCurly)
    let node = AST::new(ASTType::Match, op.span.join(expr.span))
    node.u.match_stmt.expr = expr

    let cases = Vector<&MatchCase>::new()
    .consume(TokenType::OpenCurly)
    while not .token_is(TokenType::CloseCurly) {
        if .token_is(TokenType::Else) {
            node.u.match_stmt.defolt_span = .token().span
            .consume(TokenType::Else)
            .consume(TokenType::FatArrow)
            node.u.match_stmt.defolt = .parse_statement()

        } else {
            let cond = .parse_atom(TokenType::Line)
            let body = null as &AST
            if not .consume_if(TokenType::Line) {
                .consume(TokenType::FatArrow)
                body = .parse_statement()
                if not .token_is(TokenType::CloseCurly) {
                    .consume_newline_or(TokenType::Comma)
                }
            }
            let _case = MatchCase::new(cond, body)
            cases.push(_case)
        }
    }
    node.span = op.span.join(.token().span)
    .consume(TokenType::CloseCurly)
    node.u.match_stmt.cases = cases

    return node
}

def Parser::parse_literal_suffix_type(&this, suffix: &Token): &Type {
    if not suffix? return null

    let ident = AST::new(ASTType::Identifier, suffix.span)
    ident.u.ident.name = suffix.text

    let typ = Type::new_unresolved(suffix.text, suffix.span)
    typ.u.unresolved = ident

    return typ
}

def Parser::parse_call(&this, callee: &AST): &AST {
    .consume(TokenType::OpenParen)
    let args = Vector<&Argument>::new()
    while not .token_is(TokenType::CloseParen) {
        let label = null as str
        let label_span = Span::default()

        let expr = .parse_expression(end_type: TokenType::Comma)
        if expr.type == ASTType::Identifier and .token_is(TokenType::Colon) {
            .consume(TokenType::Colon)
            label = expr.u.ident.name
            label_span = expr.span
            expr = .parse_expression(end_type: TokenType::Comma)
        }

        args.push(Argument::new(label, label_span, expr))
        if not .token_is(TokenType::CloseParen) {
            .consume(TokenType::Comma)
        }
    }

    let end = .consume(TokenType::CloseParen)
    let call_type = ASTType::Call
    let call = AST::new(call_type, callee.span.join(end.span))
    call.u.call.callee = callee
    call.u.call.args = args
    return call
}

def Parser::parse_global_value(&this, is_const: bool): &AST {
    let start_token = if is_const {
        yield .consume(TokenType::Const)
    } else {
        yield .consume(TokenType::Let)
    }

    let node = AST::new(ASTType::VarDeclaration, .token().span)
    let name = if .token_is(TokenType::Identifier) {
        yield .consume(TokenType::Identifier)
    } else {
        .error(Error::new(.token().span, "Expected identifier"))
        return node
    }

    let type = null as &Type
    if .consume_if(TokenType::Colon) { type = .parse_type(); }

    let var = Variable::new(type)
    var.sym = Symbol::new_with_parent(Variable, .ns, .ns.sym, name.text, name.span)
    var.sym.u.var = var

    if is_const {
        var.sym.type = SymbolType::Constant
    }

    .parse_extern_into_symbol(var.sym)

    node.u.var_decl.var = var

    if .consume_if(TokenType::Equals) {
        node.u.var_decl.init = .parse_expression(end_type: TokenType::Newline)
    }
    .consume_newline_or(TokenType::Semicolon)
    return node
}

def Parser::parse_atom(&this, end_type: TokenType): &AST {
    let node = null as &AST
    match .token().type {
        TokenType::If => node = .parse_if()
        TokenType::Match => node = .parse_match()
        TokenType::OpenCurly => node = .parse_block()
        TokenType::FormatStringLiteral => node = .parse_format_string()
        TokenType::Null => {
            let tok = .consume(TokenType::Null)
            node = AST::new(ASTType::Null, tok.span)
        }
        TokenType::IntLiteral => {
            node = AST::new(ASTType::IntLiteral, .token().span)
            let tok = .consume(TokenType::IntLiteral)
            node.u.num_literal = NumLiteral(
                text: tok.text,
                suffix: .parse_literal_suffix_type(tok.suffix)
            )
        }
        TokenType::FloatLiteral => {
            node = AST::new(ASTType::FloatLiteral, .token().span)
            let tok = .consume(TokenType::FloatLiteral)
            node.u.num_literal = NumLiteral(
                text: tok.text,
                suffix: .parse_literal_suffix_type(tok.suffix)
            )
        }
        TokenType::StringLiteral => {
            node = AST::new(ASTType::StringLiteral, .token().span)
            let tok = .consume(TokenType::StringLiteral)
            node.u.string_literal = tok.text
        }
        TokenType::CharLiteral => {
            node = AST::new(ASTType::CharLiteral, .token().span)
            let tok = .consume(TokenType::CharLiteral)
            node.u.char_literal = tok.text
        }
        TokenType::Identifier => node = .parse_scoped_identifier()
        TokenType::True | TokenType::False => {
            let tok = .consume(.token().type)
            node = AST::new(ASTType::BoolLiteral, tok.span)
            node.u.bool_literal = tok.type == TokenType::True
        }
        TokenType::OpenParen => {
            .consume(TokenType::OpenParen)
            node = .parse_expression(end_type: TokenType::CloseParen)
            .consume(TokenType::CloseParen)
        }
        TokenType::Dot => {
            let tok = .consume(TokenType::Dot)
            let ident = .consume(TokenType::Identifier)

            if not .curr_func? or not .curr_func.is_method or .curr_func.is_static {
                .error(Error::new(tok.span, "Cannot use dot shorthand outside of a method"))
                return AST::new(ASTType::Error, tok.span)
            }

            let lhs = AST::new(ASTType::Identifier, tok.span)
            lhs.u.ident.name = "this"

            node = AST::new(ASTType::Member, tok.span.join(ident.span))
            node.u.member.lhs = lhs
            node.u.member.rhs_name = ident.text
            node.u.member.rhs_span = ident.span
        }
        else => {
            .unhandled_type("parse_expression")
            node = AST::new(ASTType::Error, .token().span)
            .curr += 1
        }
    }
    return node
}

def Parser::parse_postfix(&this, end_type: TokenType): &AST {
    let node = .parse_atom(end_type)

    let running = true
    while running {
        if .token_is(end_type) break
        match .token().type {
            TokenType::OpenParen => node = .parse_call(node)
            TokenType::Dot => {
                .consume(TokenType::Dot)
                let name = .consume(TokenType::Identifier)
                let member = AST::new(ASTType::Member, node.span.join(name.span))

                member.u.member.lhs = node
                member.u.member.rhs_name = name.text
                member.u.member.rhs_span = name.span
                node = member
            }
            TokenType::Question => {
                let tok = .consume(TokenType::Question)
                let op = AST::new(ASTType::IsNotNull, node.span.join(tok.span))
                op.u.unary = node
                node = op
            }
            TokenType::OpenSquare => {
                .consume(TokenType::OpenSquare)
                let index = .parse_expression(end_type: TokenType::CloseSquare)
                let close = .consume(TokenType::CloseSquare)
                let op = AST::new(ASTType::Index, node.span.join(close.span))
                op.u.binary.lhs = node
                op.u.binary.rhs = index
                node = op
            }
            TokenType::MinusMinus | TokenType::PlusPlus => {
                let span = node.span.join(.token().span)
                let op = if .token_is(TokenType::MinusMinus) {
                    .consume(TokenType::MinusMinus)
                    yield ASTType::PostDecrement
                } else {
                    .consume(TokenType::PlusPlus)
                    yield ASTType::PostIncrement
                }
                node = AST::new_unop(op, span, node)
            }
            else => running = false
        }
    }

    return node
}

def Parser::parse_prefix(&this, end_type: TokenType): &AST {
    match .token().type {
        TokenType::Ampersand => {
            let amp = .consume(TokenType::Ampersand)
            let expr = .parse_prefix(end_type)
            let node = AST::new(ASTType::Address, amp.span.join(expr.span))
            node.u.unary = expr
            return node
        }
        TokenType::MinusMinus | TokenType::PlusPlus => {
            let start_span = .token().span
            let op = if .token_is(TokenType::MinusMinus) {
                .consume(TokenType::MinusMinus)
                yield ASTType::PreDecrement
            } else {
                .consume(TokenType::PlusPlus)
                yield ASTType::PreIncrement
            }
            let expr = .parse_prefix(end_type)
            return AST::new_unop(op, start_span.join(expr.span), expr)
        }
        TokenType::SizeOf => {
            let start = .consume(TokenType::SizeOf)
            .consume(TokenType::OpenParen)
            let type = .parse_type()
            let close = .consume(TokenType::CloseParen)
            let node = AST::new(ASTType::SizeOf, start.span.join(close.span))
            node.u.size_of_type = type
            return node
        }
        TokenType::Star => {
            let star = .consume(TokenType::Star)
            let expr = .parse_prefix(end_type)
            let node = AST::new(ASTType::Dereference, star.span.join(expr.span))
            node.u.unary = expr
            return node
        }
        TokenType::Minus => {
            let minus = .consume(TokenType::Minus)
            let expr = .parse_prefix(end_type)
            let node = AST::new(ASTType::Negate, minus.span.join(expr.span))
            node.u.unary = expr
            return node
        }
        TokenType::Not => {
            let tok = .consume(TokenType::Not)
            let expr = .parse_prefix(end_type)
            let node = AST::new(ASTType::Not, tok.span.join(expr.span))
            node.u.unary = expr
            return node
        }
        TokenType::Tilde => {
            let tok = .consume(TokenType::Tilde)
            let expr = .parse_prefix(end_type)
            let node = AST::new(ASTType::BitwiseNot, tok.span.join(expr.span))
            node.u.unary = expr
            return node
        }
        else => return .parse_postfix(end_type)
    }
}

def Parser::parse_cast(&this, end_type: TokenType): &AST {
    let lhs = .parse_prefix(end_type)
    while .token_is(TokenType::As) {
        if .token_is(end_type) break
        let tok = .consume(TokenType::As)
        let type_node = .parse_type()
        let op = AST::new(ASTType::Cast, lhs.span.join(type_node.span))
        op.u.cast.lhs = lhs
        op.u.cast.to = type_node
        lhs = op
    }
    return lhs
}

def Parser::parse_term(&this, end_type: TokenType): &AST {
    let lhs = .parse_cast(end_type)
    while .token_is(TokenType::Star) or
            .token_is(TokenType::Slash) or
            .token_is(TokenType::Percent) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_cast(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}


def Parser::parse_additive(&this, end_type: TokenType): &AST {
    let lhs = .parse_term(end_type)
    while .token_is(TokenType::Plus) or .token_is(TokenType::Minus) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_term(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_shift(&this, end_type: TokenType): &AST {
    let lhs = .parse_additive(end_type)
    while .token_is(TokenType::LessThan) or
            .token_is(TokenType::GreaterThan) {
        let next_token = .tokens.at(.curr + 1)
        if .token().type != next_token.type then break
        if .token_is(end_type) break

        let op = if next_token.type == TokenType::LessThan {
            yield ASTType::LeftShift
        } else {
            yield ASTType::RightShift
        }

        .curr += 2
        let rhs = .parse_additive(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_bw_and(&this, end_type: TokenType): &AST {
    let lhs = .parse_shift(end_type)
    while .token_is(TokenType::Ampersand) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_shift(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_bw_xor(&this, end_type: TokenType): &AST {
    let lhs = .parse_bw_and(end_type)
    while .token_is(TokenType::Caret) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_bw_and(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_bw_or(&this, end_type: TokenType): &AST {
    let lhs = .parse_bw_xor(end_type)
    while .token_is(TokenType::Line) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_bw_xor(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_relational(&this, end_type: TokenType): &AST {
    let operands = Vector<&AST>::new()
    let operators = Vector<&Token>::new()

    operands.push(.parse_bw_or(end_type))
    while .token_is(TokenType::LessThan) or
            .token_is(TokenType::GreaterThan) or
            .token_is(TokenType::LessThanEquals) or
            .token_is(TokenType::GreaterThanEquals) or
            .token_is(TokenType::EqualEquals) or
            .token_is(TokenType::NotEquals) {
        if .token_is(end_type) break
        operators.push(.token())
        .curr += 1
        let term = .parse_bw_or(end_type)
        operands.push(term)
    }

    if operators.size == 0 then return operands.at(0)

    let root = null as &AST
    for let i = 0; i < operators.size; i += 1 {
        let tok = operators.at(i)
        let lhs = operands.at(i)
        let rhs = operands.at(i+1)
        let op = AST::new_binop(ASTType::from_token(tok.type), lhs, rhs)
        if root? {
            root = AST::new_binop(ASTType::And, root, op)
        } else {
            root = op
        }
    }

    operands.free()
    operators.free()

    return root
}

def Parser::parse_logical_and(&this, end_type: TokenType): &AST {
    let lhs = .parse_relational(end_type)
    while .token_is(TokenType::And) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_relational(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_logical_or(&this, end_type: TokenType): &AST {
    let lhs = .parse_logical_and(end_type)
    while .token_is(TokenType::Or) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_logical_and(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_expression(&this, end_type: TokenType): &AST {
    let lhs = .parse_logical_or(end_type)
    while .token_is(TokenType::Equals) or
            .token_is(TokenType::PlusEquals) or
            .token_is(TokenType::MinusEquals) or
            .token_is(TokenType::StarEquals) or
            .token_is(TokenType::SlashEquals) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_expression(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_if(&this): &AST {
    let start_span = .token().span
    .consume(TokenType::If)
    let cond = .parse_expression(end_type: TokenType::Newline)
    .consume_if(TokenType::Then)
    let body = .parse_statement()

    let end_span = body.span
    let els = null as &AST
    if .consume_if(TokenType::Else) {
        els = .parse_statement()
        end_span = els.span
    }
    let node = AST::new(ASTType::If, start_span.join(end_span))
    node.u.if_stmt.cond = cond
    node.u.if_stmt.body = body
    node.u.if_stmt.els = els
    return node
}

//* Parse for-each loops syntax sugar
//*
//* This function is responsible for parsing
//*
//*      for i : expr {
//*          ...
//*      }
//*
//* and converting it into
//*
//*      for let __iter = expr; __iter.has_value(); __iter.next() {
//*          let i = __iter.get();
//*          {
//*             ...
//*          }
//*      }
def Parser::parse_for_each(&this, start_span: Span): &AST {

    let name = .consume(Identifier)
    .consume(TokenType::Colon)

    let expr = .parse_expression(end_type: TokenType::Newline)
    let iter_var_name = "__iter"

    let init = {
        let node = AST::new(ASTType::VarDeclaration, expr.span)
        let var = Variable::new(null)
        var.sym = Symbol::from_local_variable(iter_var_name, var, name.span)

        node.u.var_decl.var = var
        node.u.var_decl.init = expr

        yield node
    }

    let cond = {
        let iter_name = AST::new(ASTType::Identifier, expr.span)
        iter_name.u.ident.name = iter_var_name

        let member = AST::new(ASTType::Member, expr.span)
        member.u.member.lhs = iter_name
        member.u.member.rhs_name = "has_value"
        member.u.member.rhs_span = expr.span

        let node = AST::new(ASTType::Call, expr.span)
        node.u.call.callee = member
        node.u.call.args = Vector<&Argument>::new()
        yield node
    }

    let step = {
        let iter_name = AST::new(ASTType::Identifier, expr.span)
        iter_name.u.ident.name = iter_var_name

        let member = AST::new(ASTType::Member, expr.span)
        member.u.member.lhs = iter_name
        member.u.member.rhs_name = "next"
        member.u.member.rhs_span = expr.span

        let node = AST::new(ASTType::Call, expr.span)
        node.u.call.callee = member
        node.u.call.args = Vector<&Argument>::new()
        yield node
    }


    let loop_var_decl = {
        let var = Variable::new(null)
        var.sym = Symbol::from_local_variable(name.text, var, name.span)

        let iter_name = AST::new(ASTType::Identifier, name.span)
        iter_name.u.ident.name = iter_var_name

        let member = AST::new(ASTType::Member, expr.span)
        member.u.member.lhs = iter_name
        member.u.member.rhs_name = "cur"
        member.u.member.rhs_span = expr.span

        let call = AST::new(ASTType::Call, expr.span)
        call.u.call.callee = member
        call.u.call.args = Vector<&Argument>::new()

        let node = AST::new(ASTType::VarDeclaration, expr.span)
        node.u.var_decl.var = var
        node.u.var_decl.init = call

        yield node
    }

    let inner_body = .parse_block()

    let statements = Vector<&AST>::new()
    statements.push(loop_var_decl)
    statements.push(inner_body)

    let body = AST::new(ASTType::Block, inner_body.span)
    body.u.block.statements = statements

    let node = AST::new(ASTType::For, start_span.join(body.span))
    node.u.loop.init = init
    node.u.loop.cond = cond
    node.u.loop.step = step
    node.u.loop.body = body
    return node
}

def Parser::parse_for(&this): &AST {
    let tok = .consume(TokenType::For)

    if .token_is(Identifier) and .peek(1).type == TokenType::Colon {
        return .parse_for_each(start_span: tok.span)
    }

    let init = null as &AST
    if .token_is(TokenType::Let) {
        init = .parse_statement()
    } else {
        init = .parse_expression(end_type: TokenType::Semicolon)
        .consume(TokenType::Semicolon)
    }
    let cond = .parse_expression(end_type: TokenType::Semicolon)
    .consume(TokenType::Semicolon)
    let step = .parse_expression(end_type: TokenType::OpenCurly)
    let body = .parse_block()
    let node = AST::new(ASTType::For, tok.span.join(body.span))
    node.u.loop.init = init
    node.u.loop.cond = cond
    node.u.loop.step = step
    node.u.loop.body = body
    return node
}

def Parser::parse_statement(&this): &AST {
    let node = null as &AST
    let start_span = .token().span

    match .token().type {
        TokenType::OpenCurly => node = .parse_block()
        TokenType::Return => {
            .consume(TokenType::Return)
            let expr = null as &AST
            if not .token().seen_newline {
                expr = .parse_expression(end_type: TokenType::Newline)
            }
            node = AST::new_unop(ASTType::Return, start_span.join(.token().span), expr)
            .consume_end_of_statement()
        }
        TokenType::Yield => {
            .consume(TokenType::Yield)
            let expr = .parse_expression(end_type: TokenType::Newline)
            node = AST::new_unop(ASTType::Yield, start_span.join(.token().span), expr)
            .consume_end_of_statement()
        }
        TokenType::Break => {
            .consume(TokenType::Break)
            node = AST::new(ASTType::Break, start_span.join(.token().span))
            .consume_end_of_statement()
        }
        TokenType::Continue => {
            .consume(TokenType::Continue)
            node = AST::new(ASTType::Continue, start_span.join(.token().span))
            .consume_end_of_statement()
        }
        TokenType::While => {
            let tok = .consume(TokenType::While)
            let cond = .parse_expression(end_type: TokenType::OpenCurly)
            let body = .parse_block()
            node = AST::new(ASTType::While, tok.span.join(body.span))
            node.u.loop.cond = cond
            node.u.loop.body = body
        }
        TokenType::Assert => {
            let start = .consume(TokenType::Assert)
            let expr = .parse_expression(end_type: TokenType::Newline)

            let msg = null as &AST
            let end_span = expr.span

            if .consume_if(TokenType::Comma) {
                msg = .parse_expression(end_type: TokenType::Newline)
                end_span = msg.span
            }

            let node = AST::new(ASTType::Assert, start.span.join(end_span))
            node.u.assertion.expr = expr
            node.u.assertion.msg = msg
            return node
        }
        TokenType::Defer => {
            .consume(TokenType::Defer)
            let expr = .parse_expression(end_type: TokenType::Newline)
            node = AST::new_unop(ASTType::Defer, start_span.join(.token().span), expr)
            .consume_end_of_statement()
        }
        TokenType::Import => {
            node = .parse_import()
            .consume_end_of_statement()
        }
        TokenType::For => node = .parse_for()
        TokenType::Let => {
            .consume(TokenType::Let)
            let name = .consume(TokenType::Identifier)
            let end_span = name.span

            let type = null as &Type
            if .consume_if(TokenType::Colon) {
                type = .parse_type()
                end_span = type.span
            }
            let init = null as &AST
            if .consume_if(TokenType::Equals) {
                init = .parse_expression(end_type: TokenType::Newline)
                end_span = init.span
            }
            .consume_end_of_statement()

            node = AST::new(ASTType::VarDeclaration, start_span.join(end_span))

            let var = Variable::new(type)
            var.sym = Symbol::from_local_variable(name.text, var, name.span)

            node.u.var_decl.var = var
            node.u.var_decl.init = init
        }
        else => {
            node = .parse_expression(end_type: TokenType::Newline)
            .consume_if(TokenType::Semicolon)
        }
    }

    return node
}

def Parser::parse_block(&this): &AST {
    let start = .consume(TokenType::OpenCurly)

    let statements = Vector<&AST>::new()
    while not .token_is(TokenType::CloseCurly) {
        let statement = .parse_statement()
        statements.push(statement)
    }

    let end = .consume(TokenType::CloseCurly)

    let node = AST::new(ASTType::Block, start.span.join(end.span))
    node.u.block.statements = statements
    return node
}

def Parser::parse_template_params(&this, sym: &Symbol, out_span: &Span = null) {
    let start = .consume(TokenType::LessThan).span
    let params = Vector<&Variable>::new()
    while not .token_is(TokenType::GreaterThan) {
        let type = .consume(TokenType::Identifier)
        let var = Variable::new(Type::new_unresolved(type.text, type.span))
        var.sym = Symbol::from_local_variable(type.text, var, type.span)

        params.push(var)

        if not .token_is(TokenType::GreaterThan) {
            .consume(TokenType::Comma)
        }
    }
    let end = .consume(TokenType::GreaterThan).span
    if out_span? {
        *out_span = start.join(end)
    }

    sym.template = Template::new(params)
}

def Parser::add_doc_comment(&this, sym: &Symbol, token: &Token) {
    if not token.comment? return
    sym.comment = token.comment
    sym.comment_loc = token.comment_loc
}

def Parser::parse_function(&this): &Function {
    let start = .consume(TokenType::Def)

    let parent_type = null as &Type
    let is_method = false
    let is_static = true

    let ident = .parse_scoped_identifier(consume_template: false)
    if not ident? return null

    let name_span = ident.span

    let func = Function::new()
    let name = match ident.type {
        ASTType::Identifier => ident.u.ident.name
        ASTType::NSLookup => {
            parent_type = Type::new_unresolved("<unresolved>", ident.span)
            parent_type.u.unresolved = ident.u.lookup.lhs
            is_method = true
            yield ident.u.lookup.rhs_name
        }
        else => {
            .error(Error::new(ident.span, "Expected identifier"))
            yield "<error>"
        }
    }

    func.sym = Symbol::new_with_parent(Function, .ns, .ns.sym, name, name_span)
    func.sym.u.func = func
    .add_doc_comment(func.sym, start)

    if .token_is(TokenType::LessThan) {
        .parse_template_params(func.sym)
    }

    .consume(TokenType::OpenParen)
    while not .token_is(TokenType::CloseParen) {
        let found_amp = .consume_if(TokenType::Ampersand)
        let var_name = .consume(TokenType::Identifier)
        let type = null as &Type
        if func.params.is_empty() and is_method {
            if var_name.text.eq("this") {
                type = parent_type
                if found_amp {
                    type = Type::new_resolved(BaseType::Pointer, parent_type.span)
                    type.u.ptr = parent_type
                }
                is_static = false
            } else if found_amp {
                .error(Error::new(var_name.span, "Expected 'this' over here"))
            }
        }
        if not type? {
            .consume(TokenType::Colon)
            type = .parse_type()
        }

        let default_value = null as &AST
        if .consume_if(TokenType::Equals) {
            default_value = .parse_expression(end_type: TokenType::Comma)
        }
        let var = Variable::new(type)
        var.sym = Symbol::from_local_variable(var_name.text, var, var_name.span)
        var.default_value = default_value
        func.params.push(var)

        .add_doc_comment(var.sym, var_name)

        if not .token_is(TokenType::CloseParen) {
            .consume(TokenType::Comma)
        }
    }
    .consume(TokenType::CloseParen)

    if .consume_if(TokenType::Colon) {
        func.return_type = .parse_type()
    } else if name.eq("main") {
        func.return_type = Type::new_unresolved_base(BaseType::I32, name_span)
    } else {
        func.return_type = Type::new_unresolved_base(BaseType::Void, name_span)
        if .token_is(TokenType::Identifier) and .token().text.eq("exits") {
            .consume(TokenType::Identifier)
            func.exits = true
        }
    }

    func.is_method = is_method

    func.is_static = is_static
    func.parent_type = parent_type
    .parse_extern_into_symbol(func.sym)

    if func.sym.is_extern return func

    .curr_func = func

    if .token_is(TokenType::FatArrow) {
        let arrow = .consume(TokenType::FatArrow)

        let expr = .parse_expression(end_type: TokenType::Newline)
        let ret = AST::new(ASTType::Return, expr.span)
        ret.u.unary = expr

        let body = AST::new(ASTType::Block, ret.span)

        let statements = Vector<&AST>::new()
        statements.push(ret)
        body.u.block.statements = statements

        func.body = body

    } else {
        func.body = .parse_block()
    }

    .curr_func = null
    func.span = start.span.join(func.body.span)
    return func
}

def Parser::parse_extern_into_symbol(&this, sym: &Symbol) {
    if not .consume_if(TokenType::Extern) return
    sym.is_extern = true
    if .token_is(TokenType::OpenParen) {
        .consume(TokenType::OpenParen)
        let name = .consume(TokenType::StringLiteral)
        .consume(TokenType::CloseParen)
        sym.out_name = name.text
    } else {
        sym.out_name = sym.name
    }
}

def Parser::parse_import_path(&this): &Vector<&ImportPart> {
    let parts = Vector<&ImportPart>::new()

    while true {
        let done = false
        if .token().is_word() {
            let word = .token()
            .curr += 1

            let part = ImportPart::new(Single, word.span)
            part.u.single.name = word.text

            if .consume_if(TokenType::As) {
                let alias = .consume(TokenType::Identifier)
                part.u.single.alias = alias.text
                part.u.single.alias_span = alias.span
                done = true
            }

            parts.push(part)

        } else if .token_is(TokenType::Star) {
            let tok = .consume(TokenType::Star)

            let part = ImportPart::new(Wildcard, tok.span)
            parts.push(part)
            done = true

        } else if .token_is(TokenType::OpenCurly) {
            let open = .consume(TokenType::OpenCurly)

            let sub_paths = Vector<&Vector<&ImportPart>>::new()
            while not .token_is(TokenType::CloseCurly) {
                let sub_path = .parse_import_path()
                if not sub_path? return null

                sub_paths.push(sub_path)
                if not .consume_if(TokenType::Comma) break
            }
            let close = .consume(TokenType::CloseCurly)

            let part = ImportPart::new(Multiple, open.span.join(close.span))
            part.u.paths = sub_paths
            parts.push(part)
            done = true

        } else {
            .error(Error::new(.token().span, "Expected identifier"))
            return null
        }

        if done break
        if not .consume_if(TokenType::ColonColon) break
    }
    return parts
}

def Parser::parse_import(&this): &AST {
    let span = .token().span
    .consume(TokenType::Import)

    let parent_count = 0
    let type = match .token().type {
        TokenType::AtSign => {
            .consume(TokenType::AtSign)
            yield ImportType::ProjectNamespace
        }
        TokenType::ColonColon => {
            .consume(TokenType::ColonColon)
            yield ImportType::CurrentScope
        }
        TokenType::Dot => {
            while .consume_if(TokenType::Dot) {
                parent_count += 1
            }
            yield ImportType::ParentNamespace
        }
        else => ImportType::GlobalNamespace
    }

    // If this is a "top-level" module, this is already at the parent directory level.
    if .ns.is_top_level {
        parent_count -= 1
    }

    let parts = .parse_import_path()
    if not parts? return null

    if parts.size == 0 {
        .error(Error::new(span, "Invalid import statement"))
        return null
    }

    let node = AST::new(ASTType::Import, span)
    node.u.import_path = Import(
        parts,
        type,
        parent_count,
    )
    .load_import_path(node)
    return node
}

def Parser::parse_struct(&this): &Structure {
    let start = .token()
    let is_union = if .token_is(TokenType::Union) {
        .consume(TokenType::Union)
        yield true
    } else {
        .consume(TokenType::Struct)
        yield false
    }

    let name = .consume(TokenType::Identifier)
    let struc = Structure::new()
    struc.is_union = is_union
    struc.sym = Symbol::new_with_parent(Structure, .ns, .ns.sym, name.text, name.span)
    struc.sym.u.struc = struc
    .add_doc_comment(struc.sym, start)

    if .token_is(TokenType::LessThan) {
        .parse_template_params(struc.sym)
    }

    .parse_extern_into_symbol(struc.sym)

    // Extern structs don't need to have a body.
    if not struc.sym.is_extern or .token_is(TokenType::OpenCurly) {
        .consume(TokenType::OpenCurly)
        while not .token_is(TokenType::CloseCurly) {
            let name = .consume(TokenType::Identifier)
            .consume(TokenType::Colon)
            let type = .parse_type()

            let var = Variable::new(type)
            var.sym = Symbol::from_local_variable(name.text, var, name.span)
            .add_doc_comment(var.sym, name)

            struc.fields.push(var)
            if not .token_is(TokenType::CloseCurly) {
                .consume_newline_or(TokenType::Comma)
            }
        }
        let end = .consume(TokenType::CloseCurly)
        struc.span = start.span.join(end.span)
    }

    return struc
}

def Parser::parse_enum(&this): &Enum {
    let start = .consume(TokenType::Enum)
    let name = .consume(TokenType::Identifier)

    let enum_def = Enum::new()
    enum_def.sym = Symbol::new_with_parent(Enum, .ns, .ns.sym, name.text, start.span)
    enum_def.sym.u.enum_ = enum_def
    .add_doc_comment(enum_def.sym, start)

    .parse_extern_into_symbol(enum_def.sym)

    .consume(TokenType::OpenCurly)
    while not .token_is(TokenType::CloseCurly) {
        let name = .consume(TokenType::Identifier)
        let var = Variable::new(null)
        var.sym = Symbol::new_with_parent(Variable, .ns, enum_def.sym, name.text, name.span)
        var.sym.u.var = var
        .add_doc_comment(var.sym, name)

        if .consume_if(TokenType::Equals) {
            .parse_extern_into_symbol(var.sym)
        }

        enum_def.fields.push(var)
        if not .token_is(TokenType::CloseCurly) {
            .consume_newline_or(TokenType::Comma)
        }
    }
    let end = .consume(TokenType::CloseCurly)
    enum_def.span = start.span.join(end.span)

    return enum_def
}

def Parser::parse_namespace_until(&this, end_type: TokenType) {
    .add_doc_comment(.ns.sym, .token())
    while not .token_is(end_type) {
        match .token().type {
            Def => {
                let func = .parse_function()
                if func? then .ns.functions.push(func)
            }
            Import => {
                let import_ = .parse_import()
                if import_? {
                    .ns.imports.push(import_)   // For typechecker...
                }
            }
            Namespace => {
                let start = .consume(TokenType::Namespace).span
                let name = .consume(TokenType::Identifier)

                let old_ns = .ns
                let new_ns = Namespace::new(.ns, .ns.path)
                new_ns.sym = Symbol::new_with_parent(Namespace, old_ns, old_ns.sym, name.text, name.span)
                new_ns.sym.u.ns = new_ns

                new_ns.always_add_to_scope = true
                old_ns.namespaces.insert(name.text, new_ns)

                .ns = new_ns
                .consume(TokenType::OpenCurly)
                .parse_namespace_until(TokenType::CloseCurly)
                let end = .consume(TokenType::CloseCurly).span
                new_ns.span = start.join(end)

                .ns = old_ns
            }
            Struct | Union => {
                let struc = .parse_struct()
                if struc? then .ns.structs.push(struc)
            }
            Enum => {
                let enum_value = .parse_enum()
                if enum_value? then .ns.enums.push(enum_value)
            }
            Let => {
                let var = .parse_global_value(is_const: false)
                if var? then .ns.variables.push(var)
            }
            Const => {
                let con = .parse_global_value(is_const: true)
                if con? then .ns.constants.push(con)
            }
            AtSign => .parse_compiler_option()
            else => {
                .error(Error::new(.token().span, `Unexpected token '{.token().text}' in Parser`))
                .curr += 1
            }
        }
    }
}

def Parser::parse_compiler_option(&this) {
    .consume(TokenType::AtSign)
    let compiler = .consume(TokenType::Identifier)
    if not compiler.text.eq("compiler") {
        .error(Error::new(compiler.span, "Expected 'compiler'"))
    }

    let name = .consume(TokenType::Identifier)
    match name.text {
        "c_include" => {
            let filename = .consume(TokenType::StringLiteral)
            .program.c_includes.push(filename.text)
        }
        "c_flag" => {
            let flag = .consume(TokenType::StringLiteral)
            .program.c_flags.push(flag.text)
        }
        "c_embed" => {
            let path = .consume(TokenType::StringLiteral)

            let cur_dir = if .ns.is_top_level {
                yield .ns.path
            } else {
                yield .ns.parent.path
            }

            let full_path = f"{cur_dir}/{path.text}"
            if not std::File::exists(full_path) {
                .error(Error::new(path.span, f"File '{full_path}' does not exist"))
                return
            }

            let file = std::File::open(full_path)
            defer file.close()
            let contents = file.slurp()
            .program.c_embeds.insert(full_path, contents)
        }
        else => .error(Error::new(name.span, "Unknown compiler option"))
    }
}

def Parser::try_load_mod_for_namespace(&this, ns: &Namespace) {
    let mod_path = f"{ns.path}/mod.oc"
    if std::File::exists(mod_path) {
        ns.is_top_level = true
        let parser = Parser::make(.program, ns)
        parser.load_file(mod_path)
    } else {
        free(mod_path)
    }
}

def Parser::load_single_import_part(&this, base: &Namespace, name: str, span: Span): &Namespace {
    let sym = base.find_importable_symbol(name)

    if sym? and sym.type != Namespace then return base
    let next = if sym? then sym.u.ns else null

    let part_path = `{base.path}/{name}`
    if not next? {
        let dir_exists = directory_exists(part_path)
        let path = `{base.path}/{name}.oc`
        let file_exists = std::File::exists(path)

        if not dir_exists and not file_exists {
            .error(Error::new(span, `Could not find import path {part_path}(.oc)`))
            .program.exit_with_errors()
        }

        next = Namespace::new(parent: base, path: part_path)
        next.sym = Symbol::new_with_parent(
            Namespace,
            ns: base,
            parent: base.sym,
            name,
            span
        )
        next.sym.u.ns = next

        base.namespaces.insert(name, next)

        if file_exists {
            let parser = Parser::make(.program, next)
            parser.load_file(path.copy())
        } else {
            .try_load_mod_for_namespace(next)
        }
        free(path)
    }
    return next
}

def Parser::load_import_path_from_base(&this, parts: &Vector<&ImportPart>, base: &Namespace): bool {
    for let i = 0; i < parts.size and (not base.is_a_file or base.is_top_level); i += 1 {
        let part = parts.at(i)

        match part.type {
            Wildcard => {
                .error(Error::new(part.span, `Wildcard import is not allowed from non-module`))
                return false
            }
            Multiple => {
                let paths = part.u.paths
                let success = true
                for path : paths.iter() {
                    success = .load_import_path_from_base(path, base) and success
                }
                return success
            }
            Single => base = .load_single_import_part(base, part.u.single.name, part.span)
        }
    }
    return true
}

//* Finds the library with the name provided
def Parser::find_external_library(&this, name: str): &Namespace {
    for lib_path : .program.library_paths.iter() {
        let path = if lib_path.len() > 0 then  f"{lib_path}/{name}" else name
        if directory_exists(path) {
            let ns = Namespace::new(parent: .program.global, path: path)
            ns.sym = Symbol::new_with_parent(
                Namespace,
                ns: .program.global,
                parent: .program.global.sym,
                name: name,
                Span::default()
            )
            ns.sym.u.ns = ns
            ns.always_add_to_scope = true
            .try_load_mod_for_namespace(ns)
            return ns
        }
        free(path)
    }
    return null
}

def Parser::load_import_path(&this, import_stmt: &AST): bool {
    let path = &import_stmt.u.import_path
    let prev_project_root = .program.project_root


    let base = match path.type {
        GlobalNamespace => {
            let parts = path.parts
            assert parts.size > 0, "Expected at least one part in import path"
            assert parts.at(0).type == Single, "Expected first part to be a single import"

            let first_part = parts.at(0).u.single
            let lib_name = first_part.name

            if not .program.global.namespaces.contains(lib_name) {
                let lib = .find_external_library(lib_name)
                if not lib? {
                    .error(Error::new(import_stmt.span, `Could not find library '{lib_name}'`))
                    .program.exit_with_errors()
                }

                .program.global.namespaces.insert(lib_name, lib)
            }
            .program.project_root = .program.global.namespaces.at(lib_name)

            yield .program.global
        }
        ProjectNamespace => .program.project_root
        ParentNamespace => {
            let cur = .ns
            for let i = 0; i < path.parent_count; i += 1 {
                if not cur.parent? {
                    let first_part = path.parts.at(0)
                    .error(Error::new(first_part.span, "Cannot import from parent of root namespace"))
                    .program.exit_with_errors()
                }
                cur = cur.parent
            }
            yield cur
        }
        // We shouldn't have to import any files here, since they should already
        // be in the current scope.
        CurrentScope => {
            return true
        }
    }

    .load_import_path_from_base(path.parts, base)
    .program.project_root = prev_project_root
    return true
}

def Parser::load_file(&this, filename: str) {
    let file = std::File::open(filename, "r")
    let contents = file.slurp()
    .program.sources.insert(filename, contents)

    let lexer = Lexer::make(contents, filename)
    .tokens = lexer.lex()
    .curr = 0

    .ns.is_a_file = true

    let start = .token().span
    .parse_namespace_until(TokenType::EOF)
    let end = .token().span
    .ns.span = start.join(end)
}

def couldnt_find_stdlib() {
    println("--------------------------------------------------------------------------------")
    println("    Could not find standard library. Set OCEN_ROOT environment variable.")
    println("      Alternatively, compile from the root of `ocen` repository.")
    println("--------------------------------------------------------------------------------")
    std::exit(1)
}

def Parser::find_and_import_stdlib(&this) {
    let std_ns = .find_external_library("std")
    .program.global.namespaces.insert("std", std_ns)
}

def Parser::parse_toplevel(program: &Program, filename: str) {
    // Path to the directory of the file
    let t1 = filename.copy()
    let dir = dirname(t1).copy()
    free(t1)

    // Path to the file without the extension
    let t2 = filename.copy()
    let base = basename(t2).copy()
    // FIXME: Actually check and remove extension correctly
    base.remove_last_n(3)
    free(t2)

    // Just the name of the directory
    let t3 = dir.copy()
    let dir_base = basename(t3).copy()
    free(t3)


    // Namespace for the project directory
    let project_ns = Namespace::new(parent: program.global, path: dir)
    project_ns.sym = Symbol::new(Namespace,
        ns: program.global,
        name: dir_base,
        display: "",
        out_name: "",
        Span::default()
    )
    project_ns.sym.u.ns = project_ns
    program.global.namespaces.insert(dir_base, project_ns)
    program.project_root = project_ns

    // Namespace for the file
    let ns = Namespace::new(parent: project_ns, path: filename)
    ns.sym = Symbol::new(Namespace,
        ns: project_ns,
        name: base,
        display: "",
        out_name: "",
        Span::default()
    )
    ns.sym.u.ns = ns
    project_ns.namespaces.insert(base, ns)


    let parser = Parser::make(program, ns)
    parser.find_and_import_stdlib()
    parser.load_file(filename)
}
