use "@/lexer.ae"
use "@/utils.ae"

@compiler c_include "libgen.h"
def dirname(path: string): string extern
def basename(path: string): string extern

struct Parser {
    tokens: &Vector  // &Vector<Token>
    curr: i32

    curr_func: &Function
    program: &Program
    ns: &Namespace
}

def Parser::make(program: &Program, ns: &Namespace): Parser {
    return Parser(
        tokens: null,
        curr: 0,
        curr_func: null,
        program: program,
        ns: ns
    )
}

def Parser::error_msg(&this, msg: string): &Error {
    let err = Error::new(.token().span, msg)
    .program.errors.push(err)
    return err
}

def Parser::error(&this, err: &Error): &Error {
    .program.errors.push(err)
    return err
}

def Parser::unhandled_type(&this, func: string) {
    .error_msg(`Unexpected token in {func}: {.token().type.str()}`)
}

def Parser::token(&this): &Token => .tokens.at(.curr)

def Parser::token_is(&this, type: TokenType): bool {
    if type == TokenType::Newline {
        return .token().seen_newline
    }
    return .token().type == type
}

def Parser::consume_if(&this, type: TokenType): bool {
    if .token_is(type) {
        // Newline tokens are special because they don't consume a token.
        if type != TokenType::Newline {
            .curr += 1
        }
        return true
    }
    return false
}

def Parser::consume_newline_or(&this, type: TokenType) {
    if .token_is(type) {
        .curr += 1
    } else if not .token().seen_newline {
        .error_msg(`Expected {type.str()} or newline`)
        .program.exit_with_errors()
    }
}

def Parser::consume(&this, type: TokenType): &Token {
    let tok = .token()
    if not .consume_if(type) {
        .error_msg(`Expected TokenType::{type.str()}`)
        .program.exit_with_errors()
    }
    return tok
}

def Parser::consume_end_of_statement(&this) {
    if .token_is(TokenType::CloseCurly) return
    .consume_newline_or(TokenType::Semicolon)
}

// NOTE: The parser _always_ returns an `Unresolved` base type, with the name of the type stored in
// the `name` field. The typechecker is responsible for resolving this, even for the built-in types.
def Parser::parse_type(&this): &Type => match .token().type {
    Bool | Char | I8 | I16 | I32 | I64 | U8 | U16 | U32 | U64 | F32 | F64 | UntypedPtr => {
        let token = .token()
        .curr += 1

        let ident = AST::new(ASTType::Identifier, token.span)
        ident.u.ident.name = token.text

        let typ = Type::new_unresolved(ident.u.ident.name, ident.span)
        typ.u.unresolved = ident
        yield typ
    }

    Identifier => {
        let ident = .parse_scoped_identifier()
        let typ = Type::new_unresolved("<unresolved>", ident.span)
        typ.u.unresolved = ident
        yield typ
    }

    Ampersand => {
        let amp = .consume(Ampersand)
        let base = .parse_type()
        let typ = Type::new_resolved(BaseType::Pointer, amp.span.join(base.span))
        typ.u.ptr = base
        yield typ
    }

    Fn => {
        let start_span = .token().span
        .consume(TokenType::Fn)
        .consume(TokenType::OpenParen)
        let params = Vector::new()
        while not .token_is(TokenType::CloseParen) {
            let param_type = .parse_type()

            // No names for parameters needed for function types
            let var = Variable::new(param_type)
            var.sym = Symbol::from_local_variable("", var, param_type.span)
            params.push(var)

            if not .token_is(TokenType::CloseParen) {
                .consume(TokenType::Comma)
            }
        }
        let close = .consume(TokenType::CloseParen)
        let return_type: &Type
        if .consume_if(TokenType::Colon) {
            return_type = .parse_type()
        } else {
            return_type = Type::new_unresolved_base(BaseType::Void, start_span)
        }
        let type = Type::new_resolved(BaseType::Function, start_span.join(close.span))
        type.u.func = FunctionType::from_args(params, return_type)
        yield type
    }

    OpenSquare => {
        let start_span = .token().span
        .consume(TokenType::OpenSquare)
        let elem_type = .parse_type()
        .consume(TokenType::Semicolon)
        let size_expr = .parse_expression(end_type: TokenType::CloseSquare)
        let close = .consume(TokenType::CloseSquare)
        let typ = Type::new_resolved(BaseType::Array, start_span.join(close.span))
        typ.u.arr = ArrayType::new(elem_type, size_expr)
        yield typ
    }

    else => {
        .unhandled_type("parse_type")
        yield Type::new_unresolved_base(BaseType::Error, .token().span)
    }
}

def Parser::parse_scoped_identifier(&this): &AST {
    let tok = .consume(TokenType::Identifier)
    let node = AST::new(ASTType::Identifier, tok.span)
    node.u.ident.name = tok.text

    while .token_is(TokenType::ColonColon) {
        .consume(TokenType::ColonColon)
        let name = .consume(TokenType::Identifier)
        let lookup = AST::new(ASTType::NSLookup, node.span.join(name.span))
        lookup.u.lookup = NSLookup(node, name.text, name.span)
        node = lookup
    }

    return node
}


def Parser::parse_format_string(&this): &AST {
    let fstr = .consume(TokenType::FormatStringLiteral)
    let fstr_len = fstr.text.len()

    let expr_parts = Vector::new()    // Vector<string>
    let expr_start = Vector::new()    // Vector<i32>

    let format_parts = Vector::new()  // Vector<string>
    let specifiers = Vector::new()    // Vector<string>

    let count = 0
    let cur_start = 0
    let specifier_loc = -1

    for let i = 0; i < fstr_len; i += 1 {
        if fstr.text[i] == '\\' {
            i += 1
        } else if fstr.text[i] == '{' {
            if count == 0 {
                let part = fstr.text.substring(cur_start, i - cur_start)
                format_parts.push(part)
                cur_start = i + 1
            }
            count += 1
        } else if fstr.text[i] == '}' {
            count -= 1
            if count == 0 {
                if specifier_loc > 0 {
                    let part = fstr.text.substring(cur_start, specifier_loc - cur_start)
                    expr_parts.push(part)
                    expr_start.push((fstr.text + cur_start))

                    specifier_loc += 1
                    while specifier_loc < i and fstr.text[specifier_loc] == ' ' {
                        specifier_loc += 1
                    }

                    if specifier_loc == i {
                        let loc = fstr.span.start;
                        loc.col += specifier_loc + 1
                        let span = Span(loc, loc)
                        .error(Error::new(span, "Expected format specifier"))
                        return null
                    }

                    let spec = fstr.text.substring(specifier_loc, i - specifier_loc)
                    specifiers.push(spec)
                } else {
                    let part = fstr.text.substring(cur_start, i - cur_start)
                    expr_parts.push(part)
                    expr_start.push((fstr.text + cur_start))
                    specifiers.push(null)
                }
                cur_start = i + 1
                specifier_loc = -1

            } else if count < 0 {
                .error(Error::new(fstr.span, "Unmatched '}' in format string"))
                return null
            }

        } else if fstr.text[i] == ':' and fstr.text[i - 1] != '\\' {
            // TODO: Handle errors properly
            if count == 1 and fstr.text[i - 1] != ':' and fstr.text[i + 1] != ':' {
                specifier_loc = i
            }
        }
    }
    if count != 0 {
        .error(Error::new(fstr.span, "Unmatched '{' in format string"))
        return null
    }
    let part = fstr.text.substring(cur_start, fstr_len - cur_start)
    format_parts.push(part)

    let node = AST::new(ASTType::FormatStringLiteral, fstr.span)
    node.u.fmt_str.parts = format_parts

    let fstr_start = fstr.span.start
    let expr_nodes = Vector::new()
    for let i = 0; i < expr_parts.size; i += 1 {
        let part = expr_parts.at(i) as string
        let start = (expr_start.at(i) as string) - fstr.text

        let lexer = Lexer::make(part, fstr_start.filename)
        lexer.loc = fstr_start
        lexer.loc.col += start + 1

        let tokens = lexer.lex()
        for let i = 0; i < lexer.errors.size; i += 1 {
            .error(lexer.errors.at(i))
        }
        lexer.errors.free()

        let sub_parser = Parser::make(.program, .ns)
        sub_parser.tokens = tokens
        sub_parser.curr = 0

        let expr = sub_parser.parse_expression(end_type: TokenType::CloseCurly)
        if not sub_parser.token_is(TokenType::EOF) {
            .error(Error::new(expr.span, "Invalid expression in format string"))
        }

        expr_nodes.push(expr)
    }
    node.u.fmt_str.exprs = expr_nodes
    node.u.fmt_str.specs = specifiers
    expr_parts.free()
    expr_start.free()
    return node
}

def Parser::parse_match(&this): &AST {
    let op = .consume(TokenType::Match)
    let expr = .parse_expression(end_type: TokenType::OpenCurly)
    let node = AST::new(ASTType::Match, op.span.join(expr.span))
    node.u.match_stmt.expr = expr

    let cases = Vector::new()
    .consume(TokenType::OpenCurly)
    while not .token_is(TokenType::CloseCurly) {
        if .token_is(TokenType::Else) {
            node.u.match_stmt.defolt_span = .token().span
            .consume(TokenType::Else)
            .consume(TokenType::FatArrow)
            node.u.match_stmt.defolt = .parse_statement()

        } else {
            let cond = .parse_atom(TokenType::Line)
            let body = null as &AST
            if not .consume_if(TokenType::Line) {
                .consume(TokenType::FatArrow)
                body = .parse_statement()
                if not .token_is(TokenType::CloseCurly) {
                    .consume_newline_or(TokenType::Comma)
                }
            }
            let _case = MatchCase::new(cond, body)
            cases.push(_case)
        }
    }
    node.span = op.span.join(.token().span)
    .consume(TokenType::CloseCurly)
    node.u.match_stmt.cases = cases

    return node
}

def Parser::parse_literal_suffix_type(&this, suffix: &Token): &Type {
    if not suffix? return null

    let ident = AST::new(ASTType::Identifier, suffix.span)
    ident.u.ident.name = suffix.text

    let typ = Type::new_unresolved(suffix.text, suffix.span)
    typ.u.unresolved = ident

    return typ
}

def Parser::parse_atom(&this, end_type: TokenType): &AST {
    let node = null as &AST
    match .token().type {
        TokenType::If => node = .parse_if()
        TokenType::Match => node = .parse_match()
        TokenType::FormatStringLiteral => node = .parse_format_string()
        TokenType::Null => {
            let tok = .consume(TokenType::Null)
            node = AST::new(ASTType::Null, tok.span)
        }
        TokenType::IntLiteral => {
            node = AST::new(ASTType::IntLiteral, .token().span)
            let tok = .consume(TokenType::IntLiteral)
            node.u.num_literal = NumLiteral(
                text: tok.text,
                suffix: .parse_literal_suffix_type(tok.suffix)
            )
        }
        TokenType::FloatLiteral => {
            node = AST::new(ASTType::FloatLiteral, .token().span)
            let tok = .consume(TokenType::FloatLiteral)
            node.u.num_literal = NumLiteral(
                text: tok.text,
                suffix: .parse_literal_suffix_type(tok.suffix)
            )
        }
        TokenType::StringLiteral => {
            node = AST::new(ASTType::StringLiteral, .token().span)
            let tok = .consume(TokenType::StringLiteral)
            node.u.string_literal = tok.text
        }
        TokenType::CharLiteral => {
            node = AST::new(ASTType::CharLiteral, .token().span)
            let tok = .consume(TokenType::CharLiteral)
            node.u.char_literal = tok.text
        }
        TokenType::Identifier => node = .parse_scoped_identifier()
        TokenType::True | TokenType::False => {
            let tok = .consume(.token().type)
            node = AST::new(ASTType::BoolLiteral, tok.span)
            node.u.bool_literal = tok.type == TokenType::True
        }
        TokenType::OpenParen => {
            .consume(TokenType::OpenParen)
            node = .parse_expression(end_type: TokenType::CloseParen)
            .consume(TokenType::CloseParen)
        }
        else => {
            .unhandled_type("parse_expression")
            node = AST::new(ASTType::Error, .token().span)
            .curr += 1
        }
    }
    return node
}

def Parser::parse_call(&this, callee: &AST): &AST {
    .consume(TokenType::OpenParen)
    let args = Vector::new()
    while not .token_is(TokenType::CloseParen) {
        let label = null as string
        let label_span = Span::default()

        let expr = .parse_expression(end_type: TokenType::Comma)
        if expr.type == ASTType::Identifier and .token_is(TokenType::Colon) {
            .consume(TokenType::Colon)
            label = expr.u.ident.name
            label_span = expr.span
            expr = .parse_expression(end_type: TokenType::Comma)
        }

        args.push(Argument::new(label, label_span, expr))
        if not .token_is(TokenType::CloseParen) {
            .consume(TokenType::Comma)
        }
    }

    let end = .consume(TokenType::CloseParen)
    let call_type = ASTType::Call
    let call = AST::new(call_type, callee.span.join(end.span))
    call.u.call.callee = callee
    call.u.call.args = args
    return call
}

def Parser::parse_postfix(&this, end_type: TokenType): &AST {
    let node = .parse_atom(end_type)

    let running = true
    while running {
        if .token_is(end_type) break
        match .token().type {
            TokenType::OpenParen => node = .parse_call(node)
            TokenType::Dot => {
                .consume(TokenType::Dot)
                let name = .consume(TokenType::Identifier)
                let member = AST::new(ASTType::Member, node.span.join(name.span))

                member.u.member.lhs = node
                member.u.member.rhs_name = name.text
                member.u.member.rhs_span = name.span
                node = member
            }
            TokenType::Question => {
                let tok = .consume(TokenType::Question)
                let op = AST::new(ASTType::IsNotNull, node.span.join(tok.span))
                op.u.unary = node
                node = op
            }
            TokenType::As => {
                let tok = .consume(TokenType::As)
                let type_node = .parse_type()
                let op = AST::new(ASTType::Cast, node.span.join(type_node.span))
                op.u.cast.lhs = node
                op.u.cast.to = type_node
                node = op
            }
            TokenType::OpenSquare => {
                .consume(TokenType::OpenSquare)
                let index = .parse_expression(end_type: TokenType::CloseSquare)
                let close = .consume(TokenType::CloseSquare)
                let op = AST::new(ASTType::Index, node.span.join(close.span))
                op.u.binary.lhs = node
                op.u.binary.rhs = index
                node = op
            }
            else => running = false
        }
    }

    return node
}

def Parser::parse_prefix(&this, end_type: TokenType): &AST {
    match .token().type {
        TokenType::Ampersand => {
            let amp = .consume(TokenType::Ampersand)
            let expr = .parse_prefix(end_type)
            let node = AST::new(ASTType::Address, amp.span.join(expr.span))
            node.u.unary = expr
            return node
        }
        TokenType::SizeOf => {
            let start = .consume(TokenType::SizeOf)
            .consume(TokenType::OpenParen)
            let type = .parse_type()
            let close = .consume(TokenType::CloseParen)
            let node = AST::new(ASTType::SizeOf, start.span.join(close.span))
            node.u.size_of_type = type
            return node
        }
        TokenType::Star => {
            let star = .consume(TokenType::Star)
            let expr = .parse_prefix(end_type)
            let node = AST::new(ASTType::Dereference, star.span.join(expr.span))
            node.u.unary = expr
            return node
        }
        TokenType::Minus => {
            let minus = .consume(TokenType::Minus)
            let expr = .parse_prefix(end_type)
            let node = AST::new(ASTType::Negate, minus.span.join(expr.span))
            node.u.unary = expr
            return node
        }
        TokenType::Not => {
            let tok = .consume(TokenType::Not)
            let expr = .parse_prefix(end_type)
            let node = AST::new(ASTType::Not, tok.span.join(expr.span))
            node.u.unary = expr
            return node
        }
        TokenType::Dot => {
            let tok = .consume(TokenType::Dot)
            let ident = .consume(TokenType::Identifier)

            if not .curr_func? or not .curr_func.is_method or .curr_func.is_static {
                .error(Error::new(tok.span, "Cannot use dot shorthand outside of a method"))
                return AST::new(ASTType::Error, tok.span)
            }

            let lhs = AST::new(ASTType::Identifier, tok.span)
            lhs.u.ident.name = "this"

            let node = AST::new(ASTType::Member, tok.span.join(ident.span))
            node.u.member.lhs = lhs
            node.u.member.rhs_name = ident.text
            node.u.member.rhs_span = ident.span
            return node
        }
        else => return .parse_postfix(end_type)
    }
}

def Parser::parse_term(&this, end_type: TokenType): &AST {
    let lhs = .parse_prefix(end_type)
    while .token_is(TokenType::Star) or
            .token_is(TokenType::Slash) or
            .token_is(TokenType::Percent) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_prefix(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}


def Parser::parse_additive(&this, end_type: TokenType): &AST {
    let lhs = .parse_term(end_type)
    while .token_is(TokenType::Plus) or .token_is(TokenType::Minus) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_term(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_shift(&this, end_type: TokenType): &AST {
    let lhs = .parse_additive(end_type)
    while .token_is(TokenType::LessThanLessThan) or
            .token_is(TokenType::GreaterThanGreaterThan) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_additive(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_bw_and(&this, end_type: TokenType): &AST {
    let lhs = .parse_shift(end_type)
    while .token_is(TokenType::Ampersand) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_shift(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_bw_xor(&this, end_type: TokenType): &AST {
    let lhs = .parse_bw_and(end_type)
    while .token_is(TokenType::Caret) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_bw_and(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_bw_or(&this, end_type: TokenType): &AST {
    let lhs = .parse_bw_xor(end_type)
    while .token_is(TokenType::Line) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_bw_xor(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_relational(&this, end_type: TokenType): &AST {
    let operands = Vector::new()
    let operators = Vector::new()

    operands.push(.parse_bw_or(end_type))
    while .token_is(TokenType::LessThan) or
            .token_is(TokenType::GreaterThan) or
            .token_is(TokenType::LessThanEquals) or
            .token_is(TokenType::GreaterThanEquals) or
            .token_is(TokenType::EqualEquals) or
            .token_is(TokenType::NotEquals) {
        if .token_is(end_type) break
        operators.push(.token())
        .curr += 1
        let term = .parse_bw_or(end_type)
        operands.push(term)
    }

    if operators.size == 0 then return operands.at(0)

    let root = null as &AST
    for let i = 0; i < operators.size; i += 1 {
        let tok = operators.at(i) as &Token
        let lhs = operands.at(i) as &AST
        let rhs = operands.at(i+1) as &AST
        let op = AST::new_binop(ASTType::from_token(tok.type), lhs, rhs)
        if root? {
            root = AST::new_binop(ASTType::And, root, op)
        } else {
            root = op
        }
    }

    operands.free()
    operators.free()

    return root
}

def Parser::parse_global_value(&this, is_const: bool): &AST {
    let start_token = if is_const {
        yield .consume(TokenType::Const)
    } else {
        yield .consume(TokenType::Let)
    }

    let node = AST::new(ASTType::VarDeclaration, .token().span)
    let name = if .token_is(TokenType::Identifier) {
        yield .consume(TokenType::Identifier)
    } else {
        .error(Error::new(.token().span, "Expected identifier"))
        return node
    }

    let type = null as &Type
    if .consume_if(TokenType::Colon) { type = .parse_type(); }

    let var = Variable::new(type)
    var.sym = Symbol::from_local_variable(name.text, var, name.span)
    if is_const {
        var.sym.type = SymbolType::Constant
    }

    node.u.var_decl.var = var

    if .consume_if(TokenType::Equals) {
        node.u.var_decl.init = .parse_expression(end_type: TokenType::Newline)
    } else if is_const {
        .error(Error::new(start_token.span, "Constant must be initialized"))
    }
    .consume_newline_or(TokenType::Semicolon)
    return node
}

def Parser::parse_logical_and(&this, end_type: TokenType): &AST {
    let lhs = .parse_relational(end_type)
    while .token_is(TokenType::And) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_relational(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_logical_or(&this, end_type: TokenType): &AST {
    let lhs = .parse_logical_and(end_type)
    while .token_is(TokenType::Or) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_logical_and(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_expression(&this, end_type: TokenType): &AST {
    let lhs = .parse_logical_or(end_type)
    while .token_is(TokenType::Equals) or
            .token_is(TokenType::PlusEquals) or
            .token_is(TokenType::MinusEquals) or
            .token_is(TokenType::StarEquals) or
            .token_is(TokenType::SlashEquals) {
        if .token_is(end_type) break
        let op = ASTType::from_token(.token().type)
        .curr += 1
        let rhs = .parse_expression(end_type)
        lhs = AST::new_binop(op, lhs, rhs)
    }
    return lhs
}

def Parser::parse_if(&this): &AST {
    let start_span = .token().span
    .consume(TokenType::If)
    let cond = .parse_expression(end_type: TokenType::Newline)
    .consume_if(TokenType::Then)
    let body = .parse_statement()

    let end_span = body.span
    let els = null as &AST
    if .consume_if(TokenType::Else) {
        els = .parse_statement()
        end_span = els.span
    }
    let node = AST::new(ASTType::If, start_span.join(end_span))
    node.u.if_stmt.cond = cond
    node.u.if_stmt.body = body
    node.u.if_stmt.els = els
    return node
}

def Parser::parse_statement(&this): &AST {
    let node = null as &AST
    let start_span = .token().span

    match .token().type {
        TokenType::OpenCurly => node = .parse_block()
        TokenType::Return => {
            .consume(TokenType::Return)
            let expr = null as &AST
            if not .token().seen_newline {
                expr = .parse_expression(end_type: TokenType::Newline)
            }
            node = AST::new_unop(ASTType::Return, start_span.join(.token().span), expr)
            .consume_end_of_statement()
        }
        TokenType::Yield => {
            .consume(TokenType::Yield)
            let expr = .parse_expression(end_type: TokenType::Newline)
            node = AST::new_unop(ASTType::Yield, start_span.join(.token().span), expr)
            .consume_end_of_statement()
        }
        TokenType::Break => {
            .consume(TokenType::Break)
            node = AST::new(ASTType::Break, start_span.join(.token().span))
            .consume_end_of_statement()
        }
        TokenType::Continue => {
            .consume(TokenType::Continue)
            node = AST::new(ASTType::Continue, start_span.join(.token().span))
            .consume_end_of_statement()
        }
        TokenType::While => {
            let tok = .consume(TokenType::While)
            let cond = .parse_expression(end_type: TokenType::OpenCurly)
            let body = .parse_block()
            node = AST::new(ASTType::While, tok.span.join(body.span))
            node.u.loop.cond = cond
            node.u.loop.body = body
        }
        TokenType::Defer => {
            .consume(TokenType::Defer)
            let expr = .parse_expression(end_type: TokenType::Newline)
            node = AST::new_unop(ASTType::Defer, start_span.join(.token().span), expr)
            .consume_end_of_statement()
        }
        TokenType::Import => {
            node = .parse_import()
            .consume_end_of_statement()
        }
        TokenType::For => {
            let tok = .consume(TokenType::For)
            let init = null as &AST
            if .token_is(TokenType::Let) {
                init = .parse_statement()
            } else {
                init = .parse_expression(end_type: TokenType::Semicolon)
                .consume(TokenType::Semicolon)
            }
            let cond = .parse_expression(end_type: TokenType::Semicolon)
            .consume(TokenType::Semicolon)
            let step = .parse_expression(end_type: TokenType::OpenCurly)
            let body = .parse_block()
            node = AST::new(ASTType::For, tok.span.join(body.span))
            node.u.loop.init = init
            node.u.loop.cond = cond
            node.u.loop.step = step
            node.u.loop.body = body
        }
        TokenType::Let => {
            .consume(TokenType::Let)
            let name = .consume(TokenType::Identifier)
            let end_span = name.span

            let type = null as &Type
            if .consume_if(TokenType::Colon) {
                type = .parse_type()
                end_span = type.span
            }
            let init = null as &AST
            if .consume_if(TokenType::Equals) {
                init = .parse_expression(end_type: TokenType::Newline)
                end_span = init.span
            }
            .consume_end_of_statement()

            node = AST::new(ASTType::VarDeclaration, start_span.join(end_span))

            let var = Variable::new(type)
            var.sym = Symbol::from_local_variable(name.text, var, name.span)

            node.u.var_decl.var = var
            node.u.var_decl.init = init
        }
        else => {
            node = .parse_expression(end_type: TokenType::Newline)
            .consume_if(TokenType::Semicolon)
        }
    }

    return node
}

def Parser::parse_block(&this): &AST {
    let start = .consume(TokenType::OpenCurly)

    let statements = Vector::new()
    while not .token_is(TokenType::CloseCurly) {
        let statement = .parse_statement()
        statements.push(statement)
    }

    let end = .consume(TokenType::CloseCurly)

    let node = AST::new(ASTType::Block, start.span.join(end.span))
    node.u.block.statements = statements
    return node
}

def Parser::parse_function(&this): &Function {
    .consume(TokenType::Def)

    let parent_type = null as &Type
    let is_method = false
    let is_static = true

    let ident = if .token_is(TokenType::Identifier) {
        yield .parse_scoped_identifier()

    // FIXME: This is pretty hacky. To attach methods to primitive types, we need to be able
    //        to parse something like i32::foo(). However, `i32` etc are keywords, so we explicitly
    //        check those here and create the `NSLookup` object.
    } else {
        yield match .token().type {
            Bool | Char | I8 | I16 | I32 | I64 |
            U8 | U16 | U32 | U64 | F32 | F64 => {
                let tok = .consume(.token().type)

                let lhs = AST::new(ASTType::Identifier, tok.span)
                lhs.u.ident.name = tok.text

                if not .consume_if(TokenType::ColonColon) {
                    .error(Error::new(.token().span, "Expected `::` after type name"))
                    return null
                }

                let name = .consume(TokenType::Identifier)
                let lookup = AST::new(ASTType::NSLookup, tok.span.join(name.span))
                lookup.u.lookup.lhs = lhs
                lookup.u.lookup.rhs_name = name.text
                lookup.u.lookup.rhs_span = name.span
                yield lookup
            }
            else => {
                .error(Error::new(.token().span, "Unexpected token"))
                return null
            }
        }
    }
    let name_span = ident.span

    let func = Function::new()
    let name = match ident.type {
        ASTType::Identifier => ident.u.ident.name
        ASTType::NSLookup => {
            parent_type = Type::new_unresolved("<unresolved>", ident.span)
            parent_type.u.unresolved = ident.u.lookup.lhs
            is_method = true
            yield ident.u.lookup.rhs_name
        }
        else => {
            .error(Error::new(ident.span, "Expected identifier"))
            yield "<error>"
        }
    }

    func.sym = Symbol::new_with_parent(Function, .ns.sym, name, name_span)
    func.sym.u.func = func

    .consume(TokenType::OpenParen)
    while not .token_is(TokenType::CloseParen) {
        let found_amp = .consume_if(TokenType::Ampersand)
        let var_name = .consume(TokenType::Identifier)
        let type = null as &Type
        if func.params.empty() and is_method {
            if var_name.text.eq("this") {
                type = parent_type
                if found_amp {
                    type = Type::new_resolved(BaseType::Pointer, parent_type.span)
                    type.u.ptr = parent_type
                }
                is_static = false
            } else if found_amp {
                .error(Error::new(var_name.span, "Expected 'this' over here"))
            }
        }
        if not type? {
            .consume(TokenType::Colon)
            type = .parse_type()
        }

        let default_value = null as &AST
        if .consume_if(TokenType::Equals) {
            default_value = .parse_expression(end_type: TokenType::Comma)
        }
        let var = Variable::new(type)
        var.sym = Symbol::from_local_variable(var_name.text, var, var_name.span)
        var.default_value = default_value
        func.params.push(var)

        if not .token_is(TokenType::CloseParen) {
            .consume(TokenType::Comma)
        }
    }
    .consume(TokenType::CloseParen)

    if .consume_if(TokenType::Colon) {
        func.return_type = .parse_type()
    } else if name.eq("main") {
        func.return_type = Type::new_unresolved_base(BaseType::I32, name_span)
    } else {
        func.return_type = Type::new_unresolved_base(BaseType::Void, name_span)
        if .token_is(TokenType::Identifier) and .token().text.eq("exits") {
            .consume(TokenType::Identifier)
            func.exits = true
        }
    }

    func.is_method = is_method

    func.is_static = is_static
    func.parent_type = parent_type
    .parse_extern_into_symbol(func.sym)

    if func.sym.is_extern return func

    .curr_func = func

    if .token_is(TokenType::FatArrow) {
        let arrow = .consume(TokenType::FatArrow)
        let body = AST::new(ASTType::Block, arrow.span)
        let statements = Vector::new()

        let ret = AST::new(ASTType::Return, arrow.span)
        ret.u.unary = .parse_expression(end_type: TokenType::Newline)

        statements.push(ret)
        body.u.block.statements = statements
        func.body = body

    } else {
        func.body = .parse_block()
    }

    .curr_func = null

    return func
}

def Parser::parse_extern_into_symbol(&this, sym: &Symbol) {
    if not .consume_if(TokenType::Extern) return
    sym.is_extern = true
    if .token_is(TokenType::OpenParen) {
        .consume(TokenType::OpenParen)
        let name = .consume(TokenType::StringLiteral)
        .consume(TokenType::CloseParen)
        sym.out_name = name.text
    } else {
        sym.out_name = sym.name
    }
}

def Parser::parse_import_path(&this): &Vector { // &Vector<&ImportPart>
    let parts = Vector::new()

    while true {
        let done = false
        if .token().is_word() {
            let word = .token()
            .curr += 1

            let part = ImportPart::new(Single, word.span)
            part.u.single.name = word.text
            part.u.single.alias = word.text
            part.u.single.alias_span = word.span

            if .consume_if(TokenType::As) {
                let alias = .consume(TokenType::Identifier)
                part.u.single.alias = alias.text
                part.u.single.alias_span = alias.span
                done = true
            }

            parts.push(part)

        } else if .token_is(TokenType::Star) {
            let tok = .consume(TokenType::Star)

            let part = ImportPart::new(Wildcard, tok.span)
            parts.push(part)
            done = true

        } else if .token_is(TokenType::OpenCurly) {
            let open = .consume(TokenType::OpenCurly)

            let sub_paths = Vector::new()
            while not .token_is(TokenType::CloseCurly) {
                let sub_path = .parse_import_path()
                if not sub_path? return null

                sub_paths.push(sub_path)
                if not .consume_if(TokenType::Comma) break
            }
            let close = .consume(TokenType::CloseCurly)

            let part = ImportPart::new(Multiple, open.span.join(close.span))
            part.u.paths = sub_paths
            parts.push(part)
            done = true

        } else {
            .error(Error::new(.token().span, "Expected identifier"))
            return null
        }

        if done break
        if not .consume_if(TokenType::ColonColon) break
    }
    return parts
}

def Parser::parse_import(&this): &AST {
    let span = .token().span
    .consume(TokenType::Import)

    let parent_count = 0
    let type = match .token().type {
        TokenType::AtSign => {
            .consume(TokenType::AtSign)
            yield ImportType::FromRootNamespace
        }
        TokenType::Dot => {
            while .consume_if(TokenType::Dot) {
                parent_count += 1
            }
            yield ImportType::FromParentNamespace
        }
        else => ImportType::FromCurrentScope
    }

    // If this is a "top-level" module, this is already at the parent directory level.
    if .ns.is_top_level {
        parent_count -= 1
    }

    let parts = .parse_import_path()
    if not parts? return null

    if parts.size == 0 {
        .error(Error::new(span, "Invalid import statement"))
        return null
    }

    let node = AST::new(ASTType::Import, span)
    node.u.import_path = Import(
        parts,
        type,
        parent_count,
    )
    .load_import_path(node)
    return node
}

def Parser::parse_struct(&this): &Structure {
    let is_union = if .token_is(TokenType::Union) {
        .consume(TokenType::Union)
        yield true
    } else {
        .consume(TokenType::Struct)
        yield false
    }

    let name = .consume(TokenType::Identifier)
    let struc = Structure::new()
    struc.is_union = is_union
    struc.sym = Symbol::new_with_parent(Structure, .ns.sym, name.text, name.span)
    struc.sym.u.struc = struc

    .parse_extern_into_symbol(struc.sym)

    // Extern structs don't need to have a body.
    if not struc.sym.is_extern or .token_is(TokenType::OpenCurly) {
        .consume(TokenType::OpenCurly)
        while not .token_is(TokenType::CloseCurly) {
            let name = .consume(TokenType::Identifier)
            .consume(TokenType::Colon)
            let type = .parse_type()

            let var = Variable::new(type)
            var.sym = Symbol::from_local_variable(name.text, var, name.span)

            struc.fields.push(var)
            if not .token_is(TokenType::CloseCurly) {
                .consume_newline_or(TokenType::Comma)
            }
        }
        .consume(TokenType::CloseCurly)
    }

    return struc
}

def Parser::parse_enum(&this): &Enum {
    let start_span = .consume(TokenType::Enum).span
    let name = .consume(TokenType::Identifier)

    let enum_def = Enum::new()
    enum_def.sym = Symbol::new_with_parent(Enum, .ns.sym, name.text, start_span)
    enum_def.sym.u.enum_ = enum_def

    .consume(TokenType::OpenCurly)
    while not .token_is(TokenType::CloseCurly) {
        let name = .consume(TokenType::Identifier)
        let var = Variable::new(null)
        var.sym = Symbol::new_with_parent(Variable, enum_def.sym, name.text, name.span)
        var.sym.u.var = var

        enum_def.fields.push(var)
        if not .token_is(TokenType::CloseCurly) {
            .consume_newline_or(TokenType::Comma)
        }
    }
    .consume(TokenType::CloseCurly)

    return enum_def
}

def Parser::parse_namespace_until(&this, end_type: TokenType) {
    while not .token_is(end_type) {
        match .token().type {
            Def => {
                let func = .parse_function()
                if func? then .ns.functions.push(func)
            }
            Import => {
                let import_ = .parse_import()
                if import_? {
                    .ns.imports.push(import_)   // For typechecker...
                }
            }
            Namespace => {
                .consume(TokenType::Namespace)
                let name = .consume(TokenType::Identifier)

                let old_ns = .ns
                let new_ns = Namespace::new(.ns, .ns.path)
                new_ns.sym = Symbol::new_with_parent(Namespace, old_ns.sym, name.text, name.span)
                new_ns.sym.u.ns = new_ns

                new_ns.always_add_to_scope = true
                old_ns.namespaces.insert(name.text, new_ns)

                .ns = new_ns
                .consume(TokenType::OpenCurly)
                .parse_namespace_until(TokenType::CloseCurly)
                .consume(TokenType::CloseCurly)
                .ns = old_ns
            }
            Struct | Union => {
                let struc = .parse_struct()
                if struc? then .ns.structs.push(struc)
            }
            Enum => {
                let enum_value = .parse_enum()
                if enum_value? then .ns.enums.push(enum_value)
            }
            Let => {
                let var = .parse_global_value(is_const: false)
                if var? then .ns.variables.push(var)
            }
            Const => {
                let con = .parse_global_value(is_const: true)
                if con? then .ns.constants.push(con)
            }
            else => {
                .error(Error::new(.token().span, `Unexpected token '{.token().text}' in Parser`))
                .curr += 1
            }
        }
    }
}

def Parser::load_import_path_from_base(&this, parts: &Vector, base: &Namespace): bool {
    for let i = 0; i < parts.size and (not base.is_a_file or base.is_top_level); i += 1 {
        let part = parts.at(i) as &ImportPart

        match part.type {
            Wildcard => {
                .error(Error::new(part.span, `Wildcard import is not allowed from non-module`))
                return false
            }
            Multiple => {
                let paths = part.u.paths
                let success = true
                for let i = 0; i < paths.size; i += 1 {
                    let path = paths.at(i) as &Vector
                    success = .load_import_path_from_base(path, base) and success
                }
                return success
            }
            Single => {} // continue below
        }

        let part_name = part.u.single.name
        let next = base.namespaces.get(part_name) as &Namespace

        let part_path = `{base.path}/{part_name}`
        if not next? {
            let dir_exists = directory_exists(part_path)
            let path = `{base.path}/{part_name}.ae`
            let file_exists = File::exists(path)

            if not dir_exists and not file_exists {
                .error(Error::new(part.span, `Could not find import path {part_path}(.ae)`))
                .program.exit_with_errors()
            }

            next = Namespace::new(parent: base, path: part_path)
            next.sym = Symbol::new_with_parent(Namespace, base.sym, part_name, part.span)
            next.sym.u.ns = next

            base.namespaces.insert(part_name, next)

            if file_exists {
                let parser = Parser::make(.program, next)
                parser.load_file(path.copy())
            }
            free(path)
        }

        base = next
    }
    return true
}

def Parser::load_import_path(&this, import_stmt: &AST): bool {
    let path = &import_stmt.u.import_path

    let base = match path.type {
        // We shouldn't have to import any files here, since they should already
        // be in the current scope.
        FromCurrentScope => {
            return true
        }
        FromRootNamespace => .program.global
        FromParentNamespace => {
            let cur = .ns
            for let i = 0; i < path.parent_count; i += 1 {
                if not cur.parent? {
                    let first_part = path.parts.at(0) as &ImportPart
                    .error(Error::new(first_part.span, "Cannot import from parent of root namespace"))
                    .program.exit_with_errors()
                }
                cur = cur.parent
            }
            yield cur
        }
    }

    return .load_import_path_from_base(path.parts, base)
}

def Parser::load_file(&this, filename: string) {
    println(`[+] Including file: {filename}`)
    let file = File::open(filename, "r")
    let contents = file.slurp()

    let lexer = Lexer::make(contents, filename)
    .tokens = lexer.lex()
    .curr = 0

    .ns.is_a_file = true
    .parse_namespace_until(TokenType::EOF)
}

def Parser::parse_toplevel(filename: string, program: &Program) {
    let t1 = filename.copy()
    let dir = dirname(t1).copy()
    free(t1)

    let t2 = filename.copy()
    let base = basename(t2).copy()
    free(t2)

    // FIXME: hack
    base.remove_last_n(3)

    let std_ns = Namespace::new(parent: program.global, path: "./std")
    std_ns.sym = Symbol::new_with_parent(Namespace, program.global.sym, "std", Span::default())
    std_ns.sym.u.ns = std_ns

    program.global.namespaces.insert("std", std_ns)
    std_ns.always_add_to_scope = true
    std_ns.is_top_level = true

    let parser = Parser::make(program, std_ns)
    parser.load_file("./std/prelude.ae")

    let ns = Namespace::new(parent: program.global, path: filename)
    ns.sym = Symbol::new(Namespace, "", "", "", Span::default())
    ns.sym.u.ns = ns

    program.global.namespaces.insert(base, ns)
    program.global.path = dir

    parser.ns = ns
    parser.load_file(filename)
}
